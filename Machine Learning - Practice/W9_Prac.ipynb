{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fa8d21f-9464-4f8a-a1f7-2decb1f09b44",
   "metadata": {},
   "source": [
    "# W9 Prac - MLPS and Convolutional Neural Networks (CNNs) using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ff9b293-bc8e-4bfb-8b65-df636be6acd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.7.0-cp312-cp312-win_amd64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Downloading torch-2.7.0-cp312-cp312-win_amd64.whl (212.5 MB)\n",
      "   ---------------------------------------- 0.0/212.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 5.5/212.5 MB 25.7 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 10.5/212.5 MB 27.3 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 14.7/212.5 MB 23.6 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 19.1/212.5 MB 23.2 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 25.7/212.5 MB 24.6 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 32.2/212.5 MB 25.9 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 39.1/212.5 MB 27.0 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 46.4/212.5 MB 27.8 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 53.0/212.5 MB 28.3 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 60.3/212.5 MB 29.1 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 67.9/212.5 MB 29.6 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 75.0/212.5 MB 30.1 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 82.1/212.5 MB 30.2 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 88.9/212.5 MB 30.5 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 94.4/212.5 MB 30.6 MB/s eta 0:00:04\n",
      "   ------------------ -------------------- 100.9/212.5 MB 30.2 MB/s eta 0:00:04\n",
      "   ------------------- ------------------- 107.5/212.5 MB 30.4 MB/s eta 0:00:04\n",
      "   --------------------- ----------------- 114.6/212.5 MB 30.5 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 121.1/212.5 MB 30.4 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 128.5/212.5 MB 30.7 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 135.5/212.5 MB 30.9 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 142.9/212.5 MB 31.1 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 150.2/212.5 MB 31.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 157.5/212.5 MB 31.5 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 164.6/212.5 MB 31.5 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 171.7/212.5 MB 31.6 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 179.0/212.5 MB 31.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 185.6/212.5 MB 31.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 192.4/212.5 MB 31.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 199.5/212.5 MB 31.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 206.0/212.5 MB 31.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.3/212.5 MB 31.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.3/212.5 MB 31.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.3/212.5 MB 31.9 MB/s eta 0:00:01\n",
      "   --------------------------------------- 212.5/212.5 MB 29.2 MB/s eta 0:00:00\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ---------------------------------------  6.3/6.3 MB 35.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 25.7 MB/s eta 0:00:00\n",
      "Installing collected packages: sympy, torch\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.2\n",
      "    Uninstalling sympy-1.13.2:\n",
      "      Successfully uninstalled sympy-1.13.2\n",
      "Successfully installed sympy-1.14.0 torch-2.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ef8fd1c-2fa4-46a9-b359-c2caa5749771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummary\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\n",
      "Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76c3510d-3225-4468-8b59-a6de3760ab1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.22.0-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.7.0 in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from torchvision) (2.7.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from torch==2.7.0->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from torch==2.7.0->torchvision) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from torch==2.7.0->torchvision) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from torch==2.7.0->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from torch==2.7.0->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from torch==2.7.0->torchvision) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from torch==2.7.0->torchvision) (75.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch==2.7.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from jinja2->torch==2.7.0->torchvision) (2.1.3)\n",
      "Downloading torchvision-0.22.0-cp312-cp312-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 15.5 MB/s eta 0:00:00\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.22.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68954475-305c-495c-8115-8c1ba69a77aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard)\n",
      "  Downloading absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard)\n",
      "  Downloading grpcio-1.71.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from tensorboard) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from tensorboard) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from tensorboard) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from tensorboard) (4.25.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from tensorboard) (75.1.0)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from tensorboard) (1.16.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from tensorboard) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 3.4/5.5 MB 22.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 18.6 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Downloading grpcio-1.71.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.3/4.3 MB 28.6 MB/s eta 0:00:00\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Installing collected packages: tensorboard-data-server, grpcio, absl-py, tensorboard\n",
      "Successfully installed absl-py-2.2.2 grpcio-1.71.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c133237d-2adc-49a7-8423-f274c257e67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0+cpu\n",
      "Cuda Available : False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\sasha\\anaconda3\\lib\\site-packages (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: tensorboard in c:\\users\\sasha\\anaconda3\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from tensorboard) (2.2.2)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from tensorboard) (1.71.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from tensorboard) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from tensorboard) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from tensorboard) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from tensorboard) (4.25.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from tensorboard) (75.1.0)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from tensorboard) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\sasha\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn   # Building blocks for neural networks\n",
    "import torch.nn.functional as F # Various functions for building neural networks\n",
    "import torch.optim as optim  # Optimiser for neural networks\n",
    "from torchsummary import summary  # Summarise PyTorch model\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter # Tensorboard in PyTorch\n",
    "import datetime\n",
    "!rm -rf ./logs/\n",
    "print(torch.__version__) # Double check the colab has the instance of tensorflow we want\n",
    "\n",
    "# If using GPU\n",
    "print('Cuda Available : {}'.format(torch.cuda.is_available()))\n",
    "if torch.cuda.is_available():\n",
    "  print('GPU - {0}'.format(torch.cuda.get_device_name()))\n",
    "\n",
    "# Library for Progres Bar during training\n",
    "!pip install tqdm\n",
    "!pip install tensorboard\n",
    "\n",
    "from tqdm import tqdm # Progress bar during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc9d71ae-7b23-428c-83f7-6b4b5c09d090",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:08<00:00, 1.20MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 113kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:01<00:00, 916kB/s] \n",
      "100%|██████████| 4.54k/4.54k [00:00<?, ?B/s]\n"
     ]
    }
   ],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert PIL Image to tensor\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Normalize the pixel values\n",
    "])\n",
    "\n",
    "# Load MNIST training dataset with transformations\n",
    "mnist_train = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST('data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f2c3527-b813-4e3f-ab2d-18d0677739c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training, validation, and test sets\n",
    "train_size = int(0.8 * len(mnist_train))\n",
    "val_size = len(mnist_train) - train_size\n",
    "mnist_train, mnist_val = random_split(mnist_train, [train_size, val_size])\n",
    "\n",
    "# Define data loaders\n",
    "train_loader = DataLoader(mnist_train, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(mnist_val, batch_size=64)\n",
    "test_loader = DataLoader(mnist_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b97dab8-75ab-4564-91e5-5ebef1ee4d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "  def __init__(self):\n",
    "      super(MLP, self).__init__()\n",
    "      self.flatten = nn.Flatten()\n",
    "      self.fc1 = nn.Linear(28*28, 512)\n",
    "      self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "      x = self.flatten(x)\n",
    "      x = F.relu(self.fc1(x))\n",
    "      x = F.softmax(self.fc2(x), dim=1)\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "473e9d08-44eb-40a5-bad6-137d612a5209",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "  def __init__(self):\n",
    "      super(MLP, self).__init__()\n",
    "      self.model = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(28*28, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512, 10),\n",
    "        nn.Softmax(dim=1)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "      x = self.model(x)\n",
    "      return x\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec1722e1-3275-440c-b4e3-d5ccfadd937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate MLP\n",
    "model = MLP().cuda() if torch.cuda.is_available() else MLP()\n",
    "\n",
    "# Optimiser\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set up TensorBoard log directory\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/MLP\"\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "# Example training loop\n",
    "num_epochs = 5 # Vary as you wish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "37d728ae-e288-47c4-acc2-8932262beadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 750/750 [00:30<00:00, 24.62it/s]\n",
      "Epoch 2: 100%|██████████| 750/750 [00:31<00:00, 23.64it/s]\n",
      "Epoch 3: 100%|██████████| 750/750 [00:31<00:00, 23.54it/s]\n",
      "Epoch 4: 100%|██████████| 750/750 [00:31<00:00, 23.55it/s]\n",
      "Epoch 5: 100%|██████████| 750/750 [00:31<00:00, 23.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1                  [-1, 784]               0\n",
      "            Linear-2                  [-1, 512]         401,920\n",
      "              ReLU-3                  [-1, 512]               0\n",
      "            Linear-4                   [-1, 10]           5,130\n",
      "           Softmax-5                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 1.55\n",
      "Estimated Total Size (MB): 1.57\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        # When cuda is available\n",
    "        if torch.cuda.is_available():\n",
    "          inputs = inputs.cuda()\n",
    "          labels = labels.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    # Logging training loss and accuracy\n",
    "    writer.add_scalar('Loss/train', running_loss / len(train_loader), epoch)\n",
    "    writer.add_scalar('Accuracy/train', 100. * correct / total, epoch)\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:  # assume you have DataLoader for test_ds\n",
    "            # When cuda is available\n",
    "            if torch.cuda.is_available():\n",
    "              inputs = inputs.cuda()\n",
    "              labels = labels.cuda()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    # Logging validation loss and accuracy\n",
    "    writer.add_scalar('Loss/val', val_loss / len(val_loader), epoch)\n",
    "    writer.add_scalar('Accuracy/val', 100. * val_correct / val_total, epoch)\n",
    "\n",
    "# Don't forget to close the writer when done\n",
    "writer.close()\n",
    "print(\"--------------\")\n",
    "# Summarise the model\n",
    "summary(model, input_size=(1, 28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b395a82-98e2-4b22-b749-d73beba24e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7b819c4a4630d15b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7b819c4a4630d15b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3e3a7a35-769e-4546-94fe-ff6c1058df82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 750/750 [03:18<00:00,  3.78it/s]\n",
      "Epoch 2: 100%|██████████| 750/750 [03:23<00:00,  3.68it/s]\n",
      "Epoch 3: 100%|██████████| 750/750 [03:29<00:00,  3.58it/s]\n",
      "Epoch 4: 100%|██████████| 750/750 [03:27<00:00,  3.62it/s]\n",
      "Epoch 5: 100%|██████████| 750/750 [03:15<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 26, 26]             320\n",
      "            Linear-2                  [-1, 512]      11,076,096\n",
      "            Linear-3                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 11,081,546\n",
      "Trainable params: 11,081,546\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.17\n",
      "Params size (MB): 42.27\n",
      "Estimated Total Size (MB): 42.44\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Set up TensorBoard writer\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/CNN\"\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "# Define CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3)  # MNIST has 1 color (channel)\n",
    "        self.fc1 = nn.Linear(32 * 26 * 26, 512)  # Flatten after Conv2D\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model (using cuda if it is available)\n",
    "model = CNN().cuda() if torch.cuda.is_available() else CNN()\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5  # Vary as you wish\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        # When cuda is available\n",
    "        if torch.cuda.is_available():\n",
    "          inputs = inputs.cuda()\n",
    "          labels = labels.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    # Log loss and accuracy to TensorBoard\n",
    "    writer.add_scalar('Loss/train', running_loss / len(train_loader), epoch)\n",
    "    writer.add_scalar('Accuracy/train', 100. * correct / total, epoch)\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            # When cuda is available\n",
    "            if torch.cuda.is_available():\n",
    "              inputs = inputs.cuda()\n",
    "              labels = labels.cuda()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    # Log validation loss and accuracy\n",
    "    writer.add_scalar('Loss/val', val_loss / len(test_loader), epoch)\n",
    "    writer.add_scalar('Accuracy/val', 100. * val_correct / val_total, epoch)\n",
    "\n",
    "# Don't forget to close the writer\n",
    "writer.close()\n",
    "print(\"--------------\")\n",
    "\n",
    "# Summarise the model\n",
    "summary(model, input_size=(1, 28, 28))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c42af9b0-2710-48b6-8abb-294cc2afc2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 81140), started 0:29:15 ago. (Use '!kill 81140' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e63524416ea26834\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e63524416ea26834\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir ./logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0b78b2-e624-4486-8713-20406d8a758f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
